{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das CRISP DM Modell teilt sich in folgende Phasen auf:\n",
    "<li> Business understanding\n",
    "<li> Data understanding\n",
    "<li> Data preparation\n",
    "<li> Modeling\n",
    "<li> Evaluating\n",
    "<li> Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benötigte Module importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Business understanding </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir betrachten das Titanic-Problem. Basierend auf Passagierdaten wollen wir vorhersagen, ob jemand den Untergang der Titanic überlebt hätte. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Data understanding </h2>\n",
    "Der Datensatz enthält Merkmale wie Geschlecht, Alter, Passagierklasse, Ticketpreis, und Anzahl der Familienmitglieder an Bord. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten einlesen\n",
    "df = pd.read_csv('titanic.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Welche Spalten sind im Datensatz vorhanden? \n",
    "# Wie viele Zeilen sind im Datensatz vorhanden?\n",
    "# Wie viele fehlende Werte sind im Datensatz vorhanden?\n",
    "# Welche Datentypen sind im Datensatz vorhanden?\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891.0</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>1.00</td>\n",
       "      <td>223.5000</td>\n",
       "      <td>446.0000</td>\n",
       "      <td>668.5</td>\n",
       "      <td>891.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891.0</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714.0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.1250</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891.0</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891.0</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.9104</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count        mean         std   min       25%       50%    75%  \\\n",
       "PassengerId  891.0  446.000000  257.353842  1.00  223.5000  446.0000  668.5   \n",
       "Survived     891.0    0.383838    0.486592  0.00    0.0000    0.0000    1.0   \n",
       "Pclass       891.0    2.308642    0.836071  1.00    2.0000    3.0000    3.0   \n",
       "Age          714.0   29.699118   14.526497  0.42   20.1250   28.0000   38.0   \n",
       "SibSp        891.0    0.523008    1.102743  0.00    0.0000    0.0000    1.0   \n",
       "Parch        891.0    0.381594    0.806057  0.00    0.0000    0.0000    0.0   \n",
       "Fare         891.0   32.204208   49.693429  0.00    7.9104   14.4542   31.0   \n",
       "\n",
       "                  max  \n",
       "PassengerId  891.0000  \n",
       "Survived       1.0000  \n",
       "Pclass         3.0000  \n",
       "Age           80.0000  \n",
       "SibSp          8.0000  \n",
       "Parch          6.0000  \n",
       "Fare         512.3292  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistische Kennzahlen anzeigen\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menge der fehlenden Werte in den Spalten\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Data preparation </h2>\n",
    "Die Daten werden zur Modellierung vorbereitet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgrund dessen, dass bei 891 Datenpunkten 687 mal die Datenpunkte zur Kabine fehlen, werden das Feature \"Cabin\" zur weiteren Analyse negiert <br>\n",
    "Dies Spalte wird demnach zunächst aus dem Datensatz entfernt. Ebenfalls werden Spalten Ticket, PassengerId und Name entfernt, da diese als nicht relevant angesehen werden <br>\n",
    "Anschließend wird der Datensatz in ein Ziel- und Featuredatensatz aufgeteilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Datensatz wird aufgeteilt in die Zielvariable und die Features\n",
    "df_target = df['Survived']\n",
    "df = df.drop(columns = [\"Name\", \"Survived\", \"PassengerId\", \"Cabin\", \"Ticket\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir ersetzen die fehlenden Werte in der Spalte \"Age\" durch den Medianwert der Spalte\n",
    "median_value = df['Age'].median() \n",
    "df['Age'] = df['Age'].fillna(median_value)\n",
    "\n",
    "# Wir ersetzen die fehlenden Werte in der Spalte \"Embarked\" durch den am häufigsten vorkommenden Wert\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die kategorischen Variablen werden in numerische Variablen umgewandelt\n",
    "encoder = LabelEncoder()\n",
    "categories = ['Sex', 'Embarked']\n",
    "\n",
    "for i in categories:\n",
    "    df[i] = encoder.fit_transform(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anteil der erklärten Varianz: [0.26512593 0.24494388 0.14233986 0.12044949 0.09520221 0.07958354\n",
      " 0.05235509]\n",
      "Anzahl Components: 7\n",
      "       Pclass       Sex       Age     SibSp     Parch      Fare  Embarked\n",
      "PC1 -0.533524 -0.343565  0.144889  0.188123  0.291205  0.614392 -0.280455\n",
      "PC2  0.343899 -0.221583 -0.499894  0.541222  0.514095 -0.047083  0.152671\n",
      "PC3 -0.200386  0.311234  0.408524  0.240118  0.192209  0.090660  0.770238\n",
      "PC4 -0.003976  0.817780 -0.179913  0.327167 -0.034936  0.248950 -0.358632\n",
      "PC5  0.286730  0.012434  0.685997  0.190487  0.371309 -0.326345 -0.407901\n",
      "PC6  0.029428  0.247588 -0.138630 -0.678285  0.670581  0.093072  0.014296\n",
      "PC7  0.688357 -0.076023  0.200107 -0.103142 -0.158717  0.659505  0.097803\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Es wird eine PCA durchgeführt, die Anzahl an relevanten Features weiter zu verringenn\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "df_pca = pca.fit_transform(df_scaled)\n",
    "\n",
    "print(f\"Anteil der erklärten Varianz: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Anzahl Components: {pca.n_components_}\")\n",
    "\n",
    "pca_components = pd.DataFrame(\n",
    "    pca.components_,\n",
    "    columns=df.columns,  # Original feature names\n",
    "    index=[f'PC{i+1}' for i in range(pca.n_components_)]  # PC names\n",
    ")\n",
    "\n",
    "print(pca_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erkenntnisse der Dimensionsreduktion mit PCA:\n",
    "<li>Pclass: Hat starke Beiträge zu PC1 und PC2, was sie zu einer wichtigen Variable macht, die beibehalten werden sollte.\n",
    "<li>Sex: Trägt stark zu PC4 bei und hat auch Einfluss auf die Varianz, also sollte diese Variable ebenfalls beibehalten werden.\n",
    "<li>Fare: Wichtiger Einfluss auf PC1 und sollte beibehalten werden.\n",
    "<li>Age: Zeigt einen moderaten Einfluss auf mehrere PCs und könnte daher auch wichtig sein.\n",
    "<li>Parch: Diese Variable hat in mehreren PCs (besonders in den späteren) geringe Ladewerte und scheint daher einen geringen Einfluss auf die Hauptkomponenten zu haben.\n",
    "<li>SibSp: Auch diese Variable hat gemischte Ladewerte, aber insgesamt scheint sie weniger Einfluss auf die Varianz zu haben, die von den ersten PCs erklärt wird.\n",
    "<li>Embarked: Diese Variable zeigt in PC3 eine starke positive Ladung (0.770), aber in den anderen PCs schwächere Einflüsse und kann daher eher vernachlässigt werden <br>\n",
    "<br><b>Schlussfolgerung:</b> Die Merkmale Parch, Sibsp & Embarked werden ebenfalls aus dem Datensatz entfernt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spalten \"SibSp\", \"Parch\", \"Embarked\" wird entfernt\n",
    "df = df.drop(columns=[\"SibSp\", \"Parch\", \"Embarked\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. Modeling & Evaluierung - XGBoost </h2>\n",
    "Es wird der K-nearest-neighbours Algorithmus angwendet, um die Daten zu modellieren. <br>\n",
    "Für jeden Durchlauf des Modells wird eine Evaluierung durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [27, 6728, 49122]\n",
    "features = df\n",
    "target = df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 27\n",
      "Cross-Validation Accuracy (Train): 0.8329\n",
      "Test Accuracy: 0.8134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       167\n",
      "           1       0.80      0.67      0.73       101\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.79      0.79       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "Random State: 6728\n",
      "Cross-Validation Accuracy (Train): 0.8009\n",
      "Test Accuracy: 0.8246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       168\n",
      "           1       0.84      0.66      0.74       100\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.83      0.79      0.80       268\n",
      "weighted avg       0.83      0.82      0.82       268\n",
      "\n",
      "Random State: 49122\n",
      "Cross-Validation Accuracy (Train): 0.7865\n",
      "Test Accuracy: 0.8358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.87       170\n",
      "           1       0.81      0.71      0.76        98\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.84      0.83       268\n",
      "\n",
      "Mean Test Accuracy: 0.8246\n",
      "Std Test Accuracy: 0.0091\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for RANDOM_STATE in states:\n",
    "    # Daten aufteilen\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, target, test_size=0.3, random_state=RANDOM_STATE\n",
    "    )\n",
    "        \n",
    "    # Modell erstellen\n",
    "    bst = XGBClassifier(n_estimators=5, max_depth=3)\n",
    "    \n",
    "    # Cross-Validation durchführen\n",
    "    cv_scores = cross_val_score(bst, X_train, y_train, cv=10)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Modell trainieren und testen\n",
    "    bst.fit(X_train, y_train)\n",
    "    preds = bst.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "    accs.append(test_accuracy)\n",
    "    \n",
    "    # Ergebnisse ausgeben\n",
    "    print(f\"Random State: {RANDOM_STATE}\")\n",
    "    print(f\"Cross-Validation Accuracy (Train): {mean_cv_score:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(classification_report(y_test, preds, zero_division=0.0))\n",
    "\n",
    "# Durchschnittliche Genauigkeit und Standardabweichung\n",
    "accs_mean = round(np.mean(accs), 4)\n",
    "accs_std = round(np.std(accs), 4)\n",
    "\n",
    "print(f\"Mean Test Accuracy: {accs_mean}\")\n",
    "print(f\"Std Test Accuracy: {accs_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5. Deployment </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Zunächst wurden die Daten aufbereitet, um ein Verständnis für sie zu entwickeln. Es lagen Daten im numerischen und kategorischen Format vor\n",
    "<li>Wir haben verschiedene Datensätze ausprobiert und getestet, um die höchste Genauigkeit zu erzielen, und sind zu dem Schluss gekommen, dass die Merkmale Pclass, Sex, Age und Fare die besten Ergebnisse liefern\n",
    "<li>Die anderen Merkmale wurden aus dem Modell entfernt\n",
    "<li>Das Modell wurde mit drei verschiedenen Random States durchgeführt, um die Robustheit der Ergebnisse zu prüfen.</li> \n",
    "<li>Da die Testgenauigkeit bei allen Random States sehr ähnlich ist (81,34% bis 83,58%) und die Standardabweichung der Genauigkeit gering ist (±0,91%), kann das Modell als robust und nicht anfällig für Overfitting angesehen werden.</li> \n",
    "<li>Die Ergebnisse zeigen eine durchschnittliche Testgenauigkeit von **82,46%**, wobei die höchste Genauigkeit bei Random State 49122 mit **83,58%** erreicht wurde.</li> <li>Die Cross-Validation-Ergebnisse stützen diese Beobachtungen, da die durchschnittlichen Validierungsgenauigkeiten zwischen **78,65%** und **83,29%** liegen. Dies zeigt, dass das Modell auch bei unterschiedlichen Aufteilungen der Trainingsdaten verlässlich bleibt.</li> \n",
    "<li>Das Modell zeigt eine starke Leistung bei der Erkennung von Nicht-Überlebenden (Klasse 0) mit einem Recall von 90% und einer Präzision von bis zu 85%. Die Vorhersage von Überlebenden (Klasse 1) ist jedoch schwächer, mit einem Recall von 66% bis 71% und einer Präzision von 80% bis 84%.</li> \n",
    "<li>Insgesamt liefert das Modell robuste Vorhersagen, insbesondere für Nicht-Überlebende, mit Potenzial zur Optimierung der Vorhersagen für Überlebende.</li>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
