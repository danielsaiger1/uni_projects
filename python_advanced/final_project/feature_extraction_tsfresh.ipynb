{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Manual Feature Extraction with Tsfresh </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Load data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.signal import decimate\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_selection import select_features\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Files read:\n",
      "ce: (2205, 60)\n",
      "cp: (2205, 60)\n",
      "eps1: (2205, 6000)\n",
      "se: (2205, 60)\n",
      "vs1: (2205, 60)\n",
      "fs1: (2205, 600)\n",
      "fs2: (2205, 600)\n",
      "ps1: (2205, 6000)\n",
      "ps2: (2205, 6000)\n",
      "ps3: (2205, 6000)\n",
      "ps4: (2205, 6000)\n",
      "ps5: (2205, 6000)\n",
      "ps6: (2205, 6000)\n",
      "ts1: (2205, 60)\n",
      "ts2: (2205, 60)\n",
      "ts3: (2205, 60)\n",
      "ts4: (2205, 60)\n",
      "target: (2205, 5)\n"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, input_path, file_names):\n",
    "        self.input_path = input_path\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def read_files(self):\n",
    "        self.data = {}\n",
    "        print(\"Reading files...\")\n",
    "        for file in self.file_names:\n",
    "            with open(self.input_path + file + '.txt', 'r') as f:\n",
    "                self.data[file] = pd.read_csv(f, header=None, sep='\\t')\n",
    "        return self.data\n",
    "    \n",
    "    def print_shape(self):\n",
    "        print(\"Files read:\")\n",
    "        for file in self.data:\n",
    "            print(f\"{file}: {self.data[file].shape}\")\n",
    "            \n",
    "    def create_target_df(self):\n",
    "        target_columns = ['Cooler_Condition', 'Valve_Condition', \n",
    "                        'Internal_Pump_Leakage', 'Hydraulic_Accumulator', \n",
    "                        'Stable_Flag']\n",
    "        self.data['target'].columns = target_columns\n",
    "        self.valve_condition = self.data['target']['Valve_Condition']\n",
    "        #del self.data['target']\n",
    "        return self.valve_condition\n",
    "\n",
    "def process_data():\n",
    "    input_path = \"input_data/\"\n",
    "    file_names = [\n",
    "        \"ce\", \"cp\", \"eps1\", \"se\", \"vs1\", \n",
    "        \"fs1\", \"fs2\", \n",
    "        \"ps1\", \"ps2\", \"ps3\", \"ps4\", \"ps5\", \"ps6\",\n",
    "        \"ts1\", \"ts2\", \"ts3\", \"ts4\", \"target\"\n",
    "    ]\n",
    "    \n",
    "    processor = DataProcessor(input_path, file_names)\n",
    "    data = processor.read_files()\n",
    "    processor.print_shape()\n",
    "    df_target = processor.create_target_df()\n",
    "    df_target = processor.valve_condition\n",
    "    return data, df_target\n",
    "\n",
    "data, df_target = process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Signal Preprocessing </h2>\n",
    "\n",
    "<h3> Input data </h3>\n",
    "\n",
    "Steps:\n",
    "\n",
    "<ul>\n",
    "    <li>If the signal frequency is > 1 Hz, the signal gets downsampled to 1 Hz </li>\n",
    "    <li>Downsampled signals are stored in a new dictionary</li>\n",
    "    <li>An ID column gets added to the downsampled signals</li>\n",
    "    <li>The downsampled signals are concatenated in one dataframe</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of ps3: (2205, 61)\n",
      "shape of eps1: (2205, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181910</td>\n",
       "      <td>0.013952</td>\n",
       "      <td>-0.022135</td>\n",
       "      <td>0.030688</td>\n",
       "      <td>-0.053816</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>-0.129521</td>\n",
       "      <td>0.205582</td>\n",
       "      <td>-0.388058</td>\n",
       "      <td>1.287525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.295209</td>\n",
       "      <td>2.331077</td>\n",
       "      <td>2.314609</td>\n",
       "      <td>2.331772</td>\n",
       "      <td>2.344258</td>\n",
       "      <td>2.274758</td>\n",
       "      <td>2.365340</td>\n",
       "      <td>2.164389</td>\n",
       "      <td>2.467429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.179051</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>-0.022035</td>\n",
       "      <td>0.030437</td>\n",
       "      <td>-0.053478</td>\n",
       "      <td>0.079484</td>\n",
       "      <td>-0.128867</td>\n",
       "      <td>0.204474</td>\n",
       "      <td>-0.385877</td>\n",
       "      <td>1.277397</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265444</td>\n",
       "      <td>2.286975</td>\n",
       "      <td>2.338045</td>\n",
       "      <td>2.303720</td>\n",
       "      <td>2.327984</td>\n",
       "      <td>2.248921</td>\n",
       "      <td>2.348491</td>\n",
       "      <td>2.192770</td>\n",
       "      <td>2.486595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170626</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>-0.021850</td>\n",
       "      <td>0.030302</td>\n",
       "      <td>-0.053269</td>\n",
       "      <td>0.078988</td>\n",
       "      <td>-0.127972</td>\n",
       "      <td>0.203145</td>\n",
       "      <td>-0.384168</td>\n",
       "      <td>1.282277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.316311</td>\n",
       "      <td>2.311031</td>\n",
       "      <td>2.280636</td>\n",
       "      <td>2.286729</td>\n",
       "      <td>2.301869</td>\n",
       "      <td>2.259966</td>\n",
       "      <td>2.346658</td>\n",
       "      <td>2.208926</td>\n",
       "      <td>2.500617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180196</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>-0.022369</td>\n",
       "      <td>0.031245</td>\n",
       "      <td>-0.054976</td>\n",
       "      <td>0.081985</td>\n",
       "      <td>-0.132920</td>\n",
       "      <td>0.211098</td>\n",
       "      <td>-0.396899</td>\n",
       "      <td>1.301068</td>\n",
       "      <td>...</td>\n",
       "      <td>2.240574</td>\n",
       "      <td>2.255356</td>\n",
       "      <td>2.253251</td>\n",
       "      <td>2.286907</td>\n",
       "      <td>2.258094</td>\n",
       "      <td>2.221323</td>\n",
       "      <td>2.304355</td>\n",
       "      <td>2.134268</td>\n",
       "      <td>2.424769</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170937</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>-0.022236</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>-0.054744</td>\n",
       "      <td>0.081630</td>\n",
       "      <td>-0.132241</td>\n",
       "      <td>0.210173</td>\n",
       "      <td>-0.396245</td>\n",
       "      <td>1.313553</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257005</td>\n",
       "      <td>2.252278</td>\n",
       "      <td>2.216802</td>\n",
       "      <td>2.261641</td>\n",
       "      <td>2.255471</td>\n",
       "      <td>2.224936</td>\n",
       "      <td>2.311261</td>\n",
       "      <td>2.131310</td>\n",
       "      <td>2.413929</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>1234.934906</td>\n",
       "      <td>3076.867147</td>\n",
       "      <td>2859.827368</td>\n",
       "      <td>3009.134788</td>\n",
       "      <td>2913.552540</td>\n",
       "      <td>2978.420808</td>\n",
       "      <td>2929.005675</td>\n",
       "      <td>2970.437712</td>\n",
       "      <td>2928.859439</td>\n",
       "      <td>2989.468366</td>\n",
       "      <td>...</td>\n",
       "      <td>2420.803885</td>\n",
       "      <td>2412.767902</td>\n",
       "      <td>2425.717742</td>\n",
       "      <td>2400.605049</td>\n",
       "      <td>2442.957722</td>\n",
       "      <td>2376.234975</td>\n",
       "      <td>2481.914084</td>\n",
       "      <td>2309.885416</td>\n",
       "      <td>2627.510636</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>1234.772948</td>\n",
       "      <td>3074.417377</td>\n",
       "      <td>2856.152473</td>\n",
       "      <td>3005.782318</td>\n",
       "      <td>2909.340225</td>\n",
       "      <td>2975.922563</td>\n",
       "      <td>2927.147952</td>\n",
       "      <td>2969.091887</td>\n",
       "      <td>2925.779865</td>\n",
       "      <td>2987.212389</td>\n",
       "      <td>...</td>\n",
       "      <td>2421.463321</td>\n",
       "      <td>2412.626815</td>\n",
       "      <td>2427.166514</td>\n",
       "      <td>2402.269938</td>\n",
       "      <td>2443.010993</td>\n",
       "      <td>2376.712279</td>\n",
       "      <td>2482.112030</td>\n",
       "      <td>2310.765586</td>\n",
       "      <td>2628.666642</td>\n",
       "      <td>2201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>1233.976886</td>\n",
       "      <td>3073.982803</td>\n",
       "      <td>2856.287302</td>\n",
       "      <td>3004.786072</td>\n",
       "      <td>2908.614940</td>\n",
       "      <td>2975.053319</td>\n",
       "      <td>2926.890941</td>\n",
       "      <td>2967.192549</td>\n",
       "      <td>2924.768865</td>\n",
       "      <td>2985.296063</td>\n",
       "      <td>...</td>\n",
       "      <td>2420.301023</td>\n",
       "      <td>2413.420808</td>\n",
       "      <td>2427.152135</td>\n",
       "      <td>2401.224877</td>\n",
       "      <td>2443.268488</td>\n",
       "      <td>2376.058788</td>\n",
       "      <td>2481.534859</td>\n",
       "      <td>2311.079525</td>\n",
       "      <td>2627.836426</td>\n",
       "      <td>2202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>1234.061432</td>\n",
       "      <td>3073.819344</td>\n",
       "      <td>2856.631926</td>\n",
       "      <td>3005.322384</td>\n",
       "      <td>2910.016808</td>\n",
       "      <td>2977.294824</td>\n",
       "      <td>2928.233888</td>\n",
       "      <td>2969.053481</td>\n",
       "      <td>2925.984835</td>\n",
       "      <td>2987.626099</td>\n",
       "      <td>...</td>\n",
       "      <td>2421.084618</td>\n",
       "      <td>2414.223594</td>\n",
       "      <td>2428.264113</td>\n",
       "      <td>2402.747634</td>\n",
       "      <td>2444.599235</td>\n",
       "      <td>2377.097999</td>\n",
       "      <td>2483.039476</td>\n",
       "      <td>2311.033054</td>\n",
       "      <td>2628.961053</td>\n",
       "      <td>2203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409</th>\n",
       "      <td>1235.080324</td>\n",
       "      <td>3075.279812</td>\n",
       "      <td>2856.571983</td>\n",
       "      <td>3005.576121</td>\n",
       "      <td>2907.964160</td>\n",
       "      <td>2974.680709</td>\n",
       "      <td>2926.596358</td>\n",
       "      <td>2966.884668</td>\n",
       "      <td>2924.282725</td>\n",
       "      <td>2985.511611</td>\n",
       "      <td>...</td>\n",
       "      <td>2421.927889</td>\n",
       "      <td>2413.745573</td>\n",
       "      <td>2426.995448</td>\n",
       "      <td>2401.224175</td>\n",
       "      <td>2443.443233</td>\n",
       "      <td>2376.325158</td>\n",
       "      <td>2482.563495</td>\n",
       "      <td>2311.693221</td>\n",
       "      <td>2628.407708</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4410 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4  \\\n",
       "0        0.181910     0.013952    -0.022135     0.030688    -0.053816   \n",
       "1        0.179051     0.013746    -0.022035     0.030437    -0.053478   \n",
       "2        0.170626     0.013492    -0.021850     0.030302    -0.053269   \n",
       "3        0.180196     0.013913    -0.022369     0.031245    -0.054976   \n",
       "4        0.170937     0.013715    -0.022236     0.031246    -0.054744   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4405  1234.934906  3076.867147  2859.827368  3009.134788  2913.552540   \n",
       "4406  1234.772948  3074.417377  2856.152473  3005.782318  2909.340225   \n",
       "4407  1233.976886  3073.982803  2856.287302  3004.786072  2908.614940   \n",
       "4408  1234.061432  3073.819344  2856.631926  3005.322384  2910.016808   \n",
       "4409  1235.080324  3075.279812  2856.571983  3005.576121  2907.964160   \n",
       "\n",
       "                5            6            7            8            9  ...  \\\n",
       "0        0.079900    -0.129521     0.205582    -0.388058     1.287525  ...   \n",
       "1        0.079484    -0.128867     0.204474    -0.385877     1.277397  ...   \n",
       "2        0.078988    -0.127972     0.203145    -0.384168     1.282277  ...   \n",
       "3        0.081985    -0.132920     0.211098    -0.396899     1.301068  ...   \n",
       "4        0.081630    -0.132241     0.210173    -0.396245     1.313553  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "4405  2978.420808  2929.005675  2970.437712  2928.859439  2989.468366  ...   \n",
       "4406  2975.922563  2927.147952  2969.091887  2925.779865  2987.212389  ...   \n",
       "4407  2975.053319  2926.890941  2967.192549  2924.768865  2985.296063  ...   \n",
       "4408  2977.294824  2928.233888  2969.053481  2925.984835  2987.626099  ...   \n",
       "4409  2974.680709  2926.596358  2966.884668  2924.282725  2985.511611  ...   \n",
       "\n",
       "               51           52           53           54           55  \\\n",
       "0        2.295209     2.331077     2.314609     2.331772     2.344258   \n",
       "1        2.265444     2.286975     2.338045     2.303720     2.327984   \n",
       "2        2.316311     2.311031     2.280636     2.286729     2.301869   \n",
       "3        2.240574     2.255356     2.253251     2.286907     2.258094   \n",
       "4        2.257005     2.252278     2.216802     2.261641     2.255471   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4405  2420.803885  2412.767902  2425.717742  2400.605049  2442.957722   \n",
       "4406  2421.463321  2412.626815  2427.166514  2402.269938  2443.010993   \n",
       "4407  2420.301023  2413.420808  2427.152135  2401.224877  2443.268488   \n",
       "4408  2421.084618  2414.223594  2428.264113  2402.747634  2444.599235   \n",
       "4409  2421.927889  2413.745573  2426.995448  2401.224175  2443.443233   \n",
       "\n",
       "               56           57           58           59    id  \n",
       "0        2.274758     2.365340     2.164389     2.467429     0  \n",
       "1        2.248921     2.348491     2.192770     2.486595     1  \n",
       "2        2.259966     2.346658     2.208926     2.500617     2  \n",
       "3        2.221323     2.304355     2.134268     2.424769     3  \n",
       "4        2.224936     2.311261     2.131310     2.413929     4  \n",
       "...           ...          ...          ...          ...   ...  \n",
       "4405  2376.234975  2481.914084  2309.885416  2627.510636  2200  \n",
       "4406  2376.712279  2482.112030  2310.765586  2628.666642  2201  \n",
       "4407  2376.058788  2481.534859  2311.079525  2627.836426  2202  \n",
       "4408  2377.097999  2483.039476  2311.033054  2628.961053  2203  \n",
       "4409  2376.325158  2482.563495  2311.693221  2628.407708  2204  \n",
       "\n",
       "[4410 rows x 61 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = ['ps3', 'eps1']\n",
    "\n",
    "df_downsampled = {}\n",
    "\n",
    "for df in df_list:\n",
    "    filtered_signals = []  # Reset for each DataFrame\n",
    "    if data[df].shape[1] == 6000:\n",
    "        downsample_factor = 100\n",
    "        for i in range(data[df].shape[0]):\n",
    "            row = data[df].iloc[i].values  # Extract row as a 1D array\n",
    "            filtered_signal = decimate(row, downsample_factor, ftype='fir')  # Downsample\n",
    "            filtered_signals.append(filtered_signal)  # Store the result\n",
    "        # Create a new DataFrame with the filtered signals and add the 'id' column\n",
    "        df_downsampled[df] = pd.DataFrame(filtered_signals)\n",
    "        df_downsampled[df][\"id\"] = df_downsampled[df].index\n",
    "\n",
    "    elif data[df].shape[1] == 600:\n",
    "        downsample_factor = 10\n",
    "        for i in range(data[df].shape[0]):\n",
    "            row = data[df].iloc[i].values  # Extract row as a 1D array\n",
    "            filtered_signal = decimate(row, downsample_factor, ftype='fir')  # Downsample\n",
    "            filtered_signals.append(filtered_signal)  # Store the result\n",
    "        # Create a new DataFrame with the filtered signals and add the 'id' column\n",
    "        df_downsampled[df] = pd.DataFrame(filtered_signals)\n",
    "        df_downsampled[df][\"id\"] = df_downsampled[df].index\n",
    "\n",
    "    else:\n",
    "        df_downsampled[df] = data[df]\n",
    "        df_downsampled[df][\"id\"] = df_downsampled[df].index\n",
    "        \n",
    "        \n",
    "for i in df_downsampled.keys():\n",
    "    print(f\"shape of {i}: {df_downsampled[i].shape}\")\n",
    "    \n",
    "# Combine all DataFrames\n",
    "df_combined = pd.concat([df_downsampled[df] for df in df_list], ignore_index=True)\n",
    "\n",
    "df_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.signal import resample_poly, decimate\n",
    "# df_list = ['se', 'fs1', 'ps3']\n",
    "\n",
    "# df_resampled = {}\n",
    "\n",
    "# for df in df_list:\n",
    "#     resampled_signals = [] \n",
    "#     if data[df].shape[1] == 6000:\n",
    "#         downsample_factor = 10\n",
    "#         for i in range(data[df].shape[0]):\n",
    "#             row = data[df].iloc[i].values  # Extract row as a 1D array\n",
    "#             resampled_signal= decimate(row, downsample_factor, ftype='fir')  # Downsample\n",
    "#             resampled_signals.append(resampled_signal)  # Store the result\n",
    "#         # Create a new DataFrame with the filtered signals and add the 'id' column\n",
    "#         df_resampled[df] = pd.DataFrame(resampled_signals)\n",
    "#         df_resampled[df][\"id\"] = df_resampled[df].index\n",
    "\n",
    "#     elif data[df].shape[1] == 60:\n",
    "#         target_rate = 10\n",
    "#         up_factor =  10\n",
    "#         for i in range(data[df].shape[0]):\n",
    "#             row = data[df].iloc[i].values  # Extract row as a 1D array\n",
    "#             resampled_signal = resample_poly(row, up=up_factor, down=1)\n",
    "#             resampled_signals.append(resampled_signal)  # Store the result\n",
    "#         # Create a new DataFrame with the filtered signals and add the 'id' column\n",
    "#         df_resampled[df] = pd.DataFrame(resampled_signals)\n",
    "#         df_resampled[df][\"id\"] = df_resampled[df].index\n",
    "\n",
    "#     else:\n",
    "#         df_resampled[df] = data[df]\n",
    "#         df_resampled[df][\"id\"] = df_resampled[df].index\n",
    "\n",
    "# # Combine all DataFrames\n",
    "\n",
    "# for i in df_resampled.keys():\n",
    "#     print(f\"shape of {i}: {df_resampled[i].shape}\")\n",
    "    \n",
    "# df_combined = pd.concat([df_resampled[df] for df in df_list], ignore_index=True)\n",
    "\n",
    "# df_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Transform Input Data into long format </h3>\n",
    "\n",
    "Since Tsfresh needs the input data in the long format, we transform our input DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_long = pd.melt(df_combined, id_vars=['id'], var_name='time', value_name='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Target Data</h3>\n",
    "\n",
    "Steps:\n",
    "\n",
    "<li>Encode Target labels</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Extract Features </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 30/30 [00:04<00:00,  6.77it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verwende minimierte Einstellungen\n",
    "settings = MinimalFCParameters()\n",
    "\n",
    "# Feature-Extraktion\n",
    "extracted_features = extract_features(df_combined_long, \n",
    "                                      column_id=\"id\", \n",
    "                                      column_sort=\"time\", \n",
    "                                      default_fc_parameters=settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the features\n",
    "features = extracted_features.dropna(axis=1)\n",
    "\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features = features.dropna(how = \"all\", axis= \"columns\")\n",
    "\n",
    "# Feature-Selektion basierend auf Zielwerten\n",
    "features = select_features(features, y=y_encoded)\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "features = selector.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready for Modelling!\n",
      "Shape features: (2205, 6)\n",
      "Shape target: (2205,)\n"
     ]
    }
   ],
   "source": [
    "# check shape of feature and target\n",
    "if features.shape[0] == y_encoded.shape[0]:\n",
    "    print(\"Data is ready for Modelling!\")\n",
    "    print(f\"Shape features: {features.shape}\")\n",
    "    print(f\"Shape target: {y_encoded.shape}\")\n",
    "else:\n",
    "    print(\"Shape of the Inputs and target don't match. Please check preprocesing steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Making predictions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [27, 6728, 49122]\n",
    "features = features\n",
    "target = y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4.1. AdaBoost Classifier </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\py_adv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        72\n",
      "           1       0.99      0.99      0.99        72\n",
      "           2       0.99      1.00      0.99        72\n",
      "           3       1.00      1.00      1.00       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\py_adv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 6728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        72\n",
      "           1       1.00      1.00      1.00        72\n",
      "           2       0.97      0.97      0.97        72\n",
      "           3       0.99      0.99      0.99       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\py_adv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 49122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        72\n",
      "           1       1.00      0.99      0.99        72\n",
      "           2       0.96      1.00      0.98        72\n",
      "           3       1.00      0.99      0.99       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n",
      "Mean Accuracy: 0.9917\n",
      "Std Accuracy: 0.0011\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for RANDOM_STATE in states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, target, test_size = 0.2, random_state = RANDOM_STATE, stratify = target\n",
    "    )\n",
    "    \n",
    "    model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=3),\n",
    "    n_estimators=50\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accs.append(accuracy_score(y_test, preds))\n",
    "    print(f\"Random State: {RANDOM_STATE}\")\n",
    "    print(classification_report(y_test, preds, zero_division=0.0))\n",
    "\n",
    "accs_mean = round(np.mean(accs), 4)\n",
    "accs_std = round(np.std(accs), 4)\n",
    "\n",
    "print(f\"Mean Accuracy: {accs_mean}\")\n",
    "print(f\"Std Accuracy: {accs_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.2. Support Vector Machines </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accs = []\n",
    "# for RANDOM_STATE in states:\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         features, target, test_size = 0.2, random_state = RANDOM_STATE, stratify = target\n",
    "#     )\n",
    "    \n",
    "#     clf = svm.SVC(kernel='linear')\n",
    "    \n",
    "#     clf.fit(X_train, y_train)\n",
    "#     preds = model.predict(X_test)\n",
    "#     accs.append(accuracy_score(y_test, preds))\n",
    "#     print(f\"Random State: {RANDOM_STATE}\")\n",
    "#     print(classification_report(y_test, preds, zero_division=0.0))\n",
    "\n",
    "# accs_mean = round(np.mean(accs), 4)\n",
    "# accs_std = round(np.std(accs), 4)\n",
    "\n",
    "# print(f\"Mean Accuracy: {accs_mean}\")\n",
    "# print(f\"Std Accuracy: {accs_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4.3. K-Nearest Neighbours</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        72\n",
      "           1       1.00      0.97      0.99        72\n",
      "           2       0.96      1.00      0.98        72\n",
      "           3       1.00      0.99      1.00       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n",
      "Random State: 6728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        72\n",
      "           1       1.00      1.00      1.00        72\n",
      "           2       0.97      0.99      0.98        72\n",
      "           3       1.00      0.99      0.99       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n",
      "Random State: 49122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        72\n",
      "           1       1.00      0.96      0.98        72\n",
      "           2       0.94      1.00      0.97        72\n",
      "           3       1.00      0.99      0.99       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.98      0.99      0.98       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n",
      "Mean Accuracy: 0.9902\n",
      "Std Accuracy: 0.0028\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for RANDOM_STATE in states:\n",
    " \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, target, test_size=0.2, random_state=RANDOM_STATE, stratify=target\n",
    "    )\n",
    "    \n",
    "    # Standardise features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    preds = knn.predict(X_test)  # Korrigiert von `model.predict` zu `knn.predict`\n",
    "    accs.append(accuracy_score(y_test, preds))\n",
    "    \n",
    "    # Ergebnisse ausgeben\n",
    "    print(f\"Random State: {RANDOM_STATE}\")\n",
    "    print(classification_report(y_test, preds, zero_division=0.0))\n",
    "\n",
    "\n",
    "accs_mean = round(np.mean(accs), 4)\n",
    "accs_std = round(np.std(accs), 4)\n",
    "\n",
    "print(f\"Mean Accuracy: {accs_mean}\")\n",
    "print(f\"Std Accuracy: {accs_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\py_adv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:06:16] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Daniel\\anaconda3\\envs\\py_adv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:06:16] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        72\n",
      "           1       1.00      0.99      0.99        72\n",
      "           2       0.99      1.00      0.99        72\n",
      "           3       1.00      1.00      1.00       225\n",
      "\n",
      "    accuracy                           1.00       441\n",
      "   macro avg       0.99      1.00      0.99       441\n",
      "weighted avg       1.00      1.00      1.00       441\n",
      "\n",
      "Random State: 6728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        72\n",
      "           1       1.00      1.00      1.00        72\n",
      "           2       0.97      0.99      0.98        72\n",
      "           3       1.00      0.99      0.99       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n",
      "Random State: 49122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        72\n",
      "           1       1.00      0.99      0.99        72\n",
      "           2       0.97      0.97      0.97        72\n",
      "           3       0.99      0.99      0.99       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n",
      "Mean Accuracy: 0.9924\n",
      "Std Accuracy: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\py_adv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:06:16] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for RANDOM_STATE in states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, target, test_size=0.2, random_state=RANDOM_STATE, stratify=target\n",
    "    )\n",
    "\n",
    "\n",
    "    xgb_clf = XGBClassifier(n_estimators = 50,\n",
    "                            learning_rate = 0.05,\n",
    "                            use_label_encoder = False,\n",
    "                            eval_metric = \"logloss\",\n",
    "                            n_jobs = -1)\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    preds = xgb_clf.predict(X_test)\n",
    "\n",
    "    accs.append(accuracy_score(y_test, preds))\n",
    "\n",
    "    print(f\"Random State: {RANDOM_STATE}\")\n",
    "    print(classification_report(y_test, preds, zero_division=0.0))\n",
    "\n",
    "accs_mean = round(np.mean(accs), 4)\n",
    "accs_std = round(np.std(accs), 4)\n",
    "\n",
    "print(f\"Mean Accuracy: {accs_mean}\")\n",
    "print(f\"Std Accuracy: {accs_std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
