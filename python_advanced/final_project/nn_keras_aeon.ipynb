{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Classification with a Neural Network using Keras (Sequential API)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Imports and load data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from aeon.classification.deep_learning import TimeCNNClassifier\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Files read:\n",
      "ce: (2205, 60)\n",
      "cp: (2205, 60)\n",
      "eps1: (2205, 6000)\n",
      "se: (2205, 60)\n",
      "vs1: (2205, 60)\n",
      "fs1: (2205, 600)\n",
      "fs2: (2205, 600)\n",
      "ps1: (2205, 6000)\n",
      "ps2: (2205, 6000)\n",
      "ps3: (2205, 6000)\n",
      "ps4: (2205, 6000)\n",
      "ps5: (2205, 6000)\n",
      "ps6: (2205, 6000)\n",
      "ts1: (2205, 60)\n",
      "ts2: (2205, 60)\n",
      "ts3: (2205, 60)\n",
      "ts4: (2205, 60)\n",
      "target: (2205, 5)\n"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, input_path, file_names):\n",
    "        self.input_path = input_path\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def read_files(self):\n",
    "        self.data = {}\n",
    "        print(\"Reading files...\")\n",
    "        for file in self.file_names:\n",
    "            with open(self.input_path + file + '.txt', 'r') as f:\n",
    "                self.data[file] = pd.read_csv(f, header=None, sep='\\t')\n",
    "        return self.data\n",
    "    \n",
    "    def print_shape(self):\n",
    "        print(\"Files read:\")\n",
    "        for file in self.data:\n",
    "            print(f\"{file}: {self.data[file].shape}\")\n",
    "            \n",
    "    def create_target_df(self):\n",
    "        target_columns = ['Cooler_Condition', 'Valve_Condition', \n",
    "                        'Internal_Pump_Leakage', 'Hydraulic_Accumulator', \n",
    "                        'Stable_Flag']\n",
    "        self.data['target'].columns = target_columns\n",
    "        self.valve_condition = self.data['target']['Valve_Condition']\n",
    "        #del self.data['target']\n",
    "        return self.valve_condition\n",
    "\n",
    "def process_data():\n",
    "    input_path = \"input_data/\"\n",
    "    file_names = [\n",
    "        \"ce\", \"cp\", \"eps1\", \"se\", \"vs1\", \n",
    "        \"fs1\", \"fs2\", \n",
    "        \"ps1\", \"ps2\", \"ps3\", \"ps4\", \"ps5\", \"ps6\",\n",
    "        \"ts1\", \"ts2\", \"ts3\", \"ts4\", \"target\"\n",
    "    ]\n",
    "    \n",
    "    processor = DataProcessor(input_path, file_names)\n",
    "    data = processor.read_files()\n",
    "    processor.print_shape()\n",
    "    df_target = processor.create_target_df()\n",
    "    df_target = processor.valve_condition\n",
    "    return data, df_target\n",
    "\n",
    "data, df_target = process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create input and target data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the six sensors which we identified as relevant during data exploration: 'eps1', 'se', 'fs1', 'ps1', 'ps2', 'ps3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.383</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.195</td>\n",
       "      <td>2.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2395.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.320</td>\n",
       "      <td>2.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2382.8</td>\n",
       "      <td>2382.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.117</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.141</td>\n",
       "      <td>2.172</td>\n",
       "      <td>2.187</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.383</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.406</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>2415.8</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.195</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.320</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2205 rows × 24660 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8     \\\n",
       "0     2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6   \n",
       "1     2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6   \n",
       "2     2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8   \n",
       "3     2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2382.8   \n",
       "4     2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2200  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4   \n",
       "2201  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6   \n",
       "2202  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6   \n",
       "2203  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6   \n",
       "2204  2415.8  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6   \n",
       "\n",
       "        9     ...   5990   5991   5992   5993   5994   5995   5996   5997  \\\n",
       "0     2409.6  ...  2.336  2.391  2.375  2.297  2.328  2.383  2.328  2.250   \n",
       "1     2409.6  ...  2.297  2.266  2.266  2.219  2.211  2.266  2.273  2.211   \n",
       "2     2395.8  ...  2.359  2.391  2.391  2.375  2.375  2.375  2.305  2.305   \n",
       "3     2382.8  ...  2.117  2.219  2.281  2.227  2.164  2.164  2.219  2.250   \n",
       "4     2373.0  ...  2.141  2.172  2.187  2.227  2.219  2.211  2.242  2.219   \n",
       "...      ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2200  2416.4  ...  2.328  2.305  2.328  2.359  2.375  2.281  2.242  2.250   \n",
       "2201  2415.6  ...  2.273  2.383  2.359  2.297  2.297  2.336  2.406  2.461   \n",
       "2202  2413.6  ...  2.227  2.242  2.219  2.211  2.273  2.273  2.250  2.219   \n",
       "2203  2413.6  ...  2.328  2.328  2.328  2.281  2.266  2.305  2.281  2.250   \n",
       "2204  2415.6  ...  2.336  2.336  2.250  2.195  2.266  2.305  2.320  2.273   \n",
       "\n",
       "       5998   5999  \n",
       "0     2.250  2.211  \n",
       "1     2.195  2.219  \n",
       "2     2.320  2.266  \n",
       "3     2.273  2.273  \n",
       "4     2.227  2.297  \n",
       "...     ...    ...  \n",
       "2200  2.266  2.273  \n",
       "2201  2.461  2.406  \n",
       "2202  2.219  2.250  \n",
       "2203  2.242  2.281  \n",
       "2204  2.227  2.250  \n",
       "\n",
       "[2205 rows x 24660 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = ['eps1', 'se', 'fs1', 'ps1', 'ps2', 'ps3']\n",
    "input_df = pd.concat([data[i] for i in df_list], axis = 1)\n",
    "input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise the input and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_target)\n",
    "\n",
    "# Standatdise the input\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205, 24660)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create the model, train it & make predictions </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>We create a neural network with 1 input layer, 2 hidden layers and 1 output layer --> 4 layers total\n",
    "<li>We use the stochastic gradient descent with a middle-sized batch size of 32 since we dont have a very big data set\n",
    "<li>We use SparseCrossEntropyLoss() for calculcating the loss. We use it because we have more than one two label classes\n",
    "<li>In the output Layer we use the softmax activation function in order to get the probabilites for classification\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [27, 6728, 49122]\n",
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(input_data_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cnn \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mTimeCNNClassifier(\n\u001b[0;32m      2\u001b[0m     n_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      3\u001b[0m     n_filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      4\u001b[0m     kernel_regularizer\u001b[38;5;241m=\u001b[39ml2(\u001b[38;5;241m0.01\u001b[39m),\n\u001b[0;32m      5\u001b[0m     n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \n\u001b[0;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )  \n\u001b[0;32m     10\u001b[0m cnn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "cnn = TimeCNNClassifier(\n",
    "    n_layers = 3,\n",
    "    n_filters=3,\n",
    "    kernel_regularizer=l2(0.01),\n",
    "    n_epochs=100, \n",
    "    batch_size=32,\n",
    "    loss = \"binary_crossentropy\",\n",
    "    verbose = True\n",
    ")  \n",
    "cnn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        36\n",
      "           1       0.86      0.83      0.85        36\n",
      "           2       0.96      0.75      0.84        36\n",
      "           3       0.97      1.00      0.98       113\n",
      "\n",
      "    accuracy                           0.93       221\n",
      "   macro avg       0.92      0.90      0.90       221\n",
      "weighted avg       0.93      0.93      0.93       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "# print the classification report for the test set\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# calculate accuracy and append to the list for later mean and std calculation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accs.append(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Classification Report for random state 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           1.00       221\n",
      "   macro avg       1.00      1.00      1.00       221\n",
      "weighted avg       1.00      1.00      1.00       221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Classification Report for random state 6728:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      0.94      0.97        36\n",
      "           3       0.99      1.00      1.00       113\n",
      "\n",
      "    accuracy                           0.99       221\n",
      "   macro avg       0.99      0.99      0.99       221\n",
      "weighted avg       0.99      0.99      0.99       221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Classification Report for random state 49122:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      0.97      0.99        36\n",
      "           2       0.97      1.00      0.99        36\n",
      "           3       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           1.00       221\n",
      "   macro avg       0.99      0.99      0.99       221\n",
      "weighted avg       1.00      1.00      1.00       221\n",
      "\n",
      "Mean Accuracy: 0.9955\n",
      "Std Accuracy: 0.0037\n"
     ]
    }
   ],
   "source": [
    "for RANDOM_STATE in states:\n",
    "    # split into train, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(input_data_scaled, y_encoded, test_size=0.2, random_state=RANDOM_STATE, stratify=y_encoded)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp)\n",
    "\n",
    "    # initiating the model with Keras sequential API\n",
    "    model = Sequential()\n",
    "\n",
    "    # creating the input layer\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "    # creating the hidden layers\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # creating the output layer\n",
    "    model.add(Dense(4, activation='softmax'))  # 4 labels and therefore 4 neurons in the output layer with softmax activation function\n",
    "\n",
    "    # compile the model using the adam optimizer and the sparse categorical crossentropy loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # creating the early stopping callback using the validation loss as the monitoring parameter\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',    \n",
    "                                   patience=10,           \n",
    "                                   restore_best_weights=True,  \n",
    "                                   verbose=1)\n",
    "\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train, \n",
    "              epochs=100, \n",
    "              batch_size=32, \n",
    "              validation_data=(X_val, y_val),  #  validation set for monitoring during training\n",
    "              verbose=0, \n",
    "              callbacks=[early_stopping])\n",
    "\n",
    "    # nake predictions and evaluate the model\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # print the classification report for the test set\n",
    "    print(f\"Classification Report for random state {RANDOM_STATE}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # calculate accuracy and append to the list for later mean and std calculation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accs.append(accuracy)\n",
    "\n",
    "# calculate mean and std of accuracy scores\n",
    "accs_mean = round(np.mean(accs), 4)\n",
    "accs_std = round(np.std(accs), 4)\n",
    "\n",
    "print(f\"Mean Accuracy: {accs_mean}\")\n",
    "print(f\"Std Accuracy: {accs_std}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
