{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Classification with a Neural Network using PyTorch</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Imports and load data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Files read:\n",
      "ce: (2205, 60)\n",
      "cp: (2205, 60)\n",
      "eps1: (2205, 6000)\n",
      "se: (2205, 60)\n",
      "vs1: (2205, 60)\n",
      "fs1: (2205, 600)\n",
      "fs2: (2205, 600)\n",
      "ps1: (2205, 6000)\n",
      "ps2: (2205, 6000)\n",
      "ps3: (2205, 6000)\n",
      "ps4: (2205, 6000)\n",
      "ps5: (2205, 6000)\n",
      "ps6: (2205, 6000)\n",
      "ts1: (2205, 60)\n",
      "ts2: (2205, 60)\n",
      "ts3: (2205, 60)\n",
      "ts4: (2205, 60)\n",
      "target: (2205, 5)\n"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, input_path: str, file_names: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the DataProcessor with the given input path and file names.\n",
    "\n",
    "        Args:\n",
    "            input_path (str): The directory path where the files are stored.\n",
    "            file_names (List[str]): List of file names to be read.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.input_path = input_path\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def read_files(self) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Reads the files specified in the file names and stores them in a dictionary.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, pd.DataFrame]: A dictionary where keys are file names and values are DataFrames.\n",
    "        \"\"\"\n",
    "        self.data = {}\n",
    "        print(\"Reading files...\")\n",
    "        for file in self.file_names:\n",
    "            with open(self.input_path + file + '.txt', 'r') as f:\n",
    "                self.data[file] = pd.read_csv(f, header=None, sep='\\t')\n",
    "        return self.data\n",
    "    \n",
    "    def print_shape(self) -> None:\n",
    "        \"\"\"\n",
    "        Prints the shape of each loaded DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(\"Files read:\")\n",
    "        for file in self.data:\n",
    "            print(f\"{file}: {self.data[file].shape}\")\n",
    "            \n",
    "    def create_target_df(self) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Renames the columns in the data['target'] and creates the wanted target DataFrame by extracting the column 'Valve_Condition'.\n",
    "\n",
    "        Returns:\n",
    "            pd.Series: A pandas Series containing the 'Valve_Condition' column from the target DataFrame.\n",
    "        \"\"\"\n",
    "        target_columns = ['Cooler_Condition', 'Valve_Condition', \n",
    "                          'Internal_Pump_Leakage', 'Hydraulic_Accumulator', \n",
    "                          'Stable_Flag']\n",
    "        self.data['target'].columns = target_columns\n",
    "        self.valve_condition = self.data['target']['Valve_Condition']\n",
    "        return self.valve_condition\n",
    "\n",
    "def process_data() -> (Dict[str, pd.DataFrame], pd.Series): # type: ignore\n",
    "    \"\"\"\n",
    "    Processes the data by reading the files and extracting the target DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[str, pd.DataFrame], pd.Series]: A tuple containing the data dictionary and the valve condition Series.\n",
    "    \"\"\"\n",
    "    input_path = \"input_data/\"\n",
    "    file_names = [\n",
    "        \"ce\", \"cp\", \"eps1\", \"se\", \"vs1\", \n",
    "        \"fs1\", \"fs2\", \n",
    "        \"ps1\", \"ps2\", \"ps3\", \"ps4\", \"ps5\", \"ps6\",\n",
    "        \"ts1\", \"ts2\", \"ts3\", \"ts4\", \"target\"\n",
    "    ]\n",
    "    \n",
    "    processor = DataProcessor(input_path, file_names)\n",
    "    data = processor.read_files()\n",
    "    processor.print_shape()\n",
    "    df_target = processor.create_target_df()\n",
    "    return data, df_target\n",
    "\n",
    "data, df_target = process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create input and target data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the six sensors which we identified as relevant during data exploration: 'eps1', 'se', 'fs1', 'ps1', 'ps2', 'ps3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.383</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.195</td>\n",
       "      <td>2.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2395.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.320</td>\n",
       "      <td>2.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2382.8</td>\n",
       "      <td>2382.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.117</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.141</td>\n",
       "      <td>2.172</td>\n",
       "      <td>2.187</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.383</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.406</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>2415.8</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.195</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.320</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2205 rows Ã— 24660 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8     \\\n",
       "0     2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6   \n",
       "1     2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6   \n",
       "2     2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8   \n",
       "3     2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2382.8   \n",
       "4     2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2200  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4   \n",
       "2201  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6   \n",
       "2202  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6   \n",
       "2203  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6   \n",
       "2204  2415.8  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6   \n",
       "\n",
       "        9     ...   5990   5991   5992   5993   5994   5995   5996   5997  \\\n",
       "0     2409.6  ...  2.336  2.391  2.375  2.297  2.328  2.383  2.328  2.250   \n",
       "1     2409.6  ...  2.297  2.266  2.266  2.219  2.211  2.266  2.273  2.211   \n",
       "2     2395.8  ...  2.359  2.391  2.391  2.375  2.375  2.375  2.305  2.305   \n",
       "3     2382.8  ...  2.117  2.219  2.281  2.227  2.164  2.164  2.219  2.250   \n",
       "4     2373.0  ...  2.141  2.172  2.187  2.227  2.219  2.211  2.242  2.219   \n",
       "...      ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2200  2416.4  ...  2.328  2.305  2.328  2.359  2.375  2.281  2.242  2.250   \n",
       "2201  2415.6  ...  2.273  2.383  2.359  2.297  2.297  2.336  2.406  2.461   \n",
       "2202  2413.6  ...  2.227  2.242  2.219  2.211  2.273  2.273  2.250  2.219   \n",
       "2203  2413.6  ...  2.328  2.328  2.328  2.281  2.266  2.305  2.281  2.250   \n",
       "2204  2415.6  ...  2.336  2.336  2.250  2.195  2.266  2.305  2.320  2.273   \n",
       "\n",
       "       5998   5999  \n",
       "0     2.250  2.211  \n",
       "1     2.195  2.219  \n",
       "2     2.320  2.266  \n",
       "3     2.273  2.273  \n",
       "4     2.227  2.297  \n",
       "...     ...    ...  \n",
       "2200  2.266  2.273  \n",
       "2201  2.461  2.406  \n",
       "2202  2.219  2.250  \n",
       "2203  2.242  2.281  \n",
       "2204  2.227  2.250  \n",
       "\n",
       "[2205 rows x 24660 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = ['eps1', 'se', 'fs1', 'ps1', 'ps2', 'ps3']\n",
    "input_df = pd.concat([data[i] for i in df_list], axis = 1)\n",
    "input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise the input and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_target)\n",
    "\n",
    "# Standatdise the input\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create the model, train it & make predictions </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>We create a neural network with 1 input layer, 2 hidden layers and 1 output layer --> 4 layers total\n",
    "<li>We use the stochastic gradient descent with a middle-sized batch size of 32 since we dont have a very big data set\n",
    "<li>We use CrossEntropyLoss() for calculcating the loss. It uses the softmax function. Because of that, we don't have to use the softmax function in our output layer for classification by using the probabilities\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [27, 6728, 49122]\n",
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Random State 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           1.00       221\n",
      "   macro avg       1.00      1.00      1.00       221\n",
      "weighted avg       1.00      1.00      1.00       221\n",
      "\n",
      "Classification Report for Random State 6728:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        36\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       0.97      0.97      0.97        36\n",
      "           3       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           0.99       221\n",
      "   macro avg       0.99      0.99      0.99       221\n",
      "weighted avg       0.99      0.99      0.99       221\n",
      "\n",
      "Classification Report for Random State 49122:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        36\n",
      "           1       1.00      0.97      0.99        36\n",
      "           2       1.00      0.97      0.99        36\n",
      "           3       0.98      1.00      0.99       113\n",
      "\n",
      "    accuracy                           0.99       221\n",
      "   macro avg       0.99      0.98      0.98       221\n",
      "weighted avg       0.99      0.99      0.99       221\n",
      "\n",
      "Mean Accuracy: 0.9925\n",
      "Std Accuracy: 0.0056\n"
     ]
    }
   ],
   "source": [
    "for RANDOM_STATE in states:\n",
    "    # split into train, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(input_data_scaled, y_encoded, test_size=0.2, random_state=RANDOM_STATE, stratify=y_encoded)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE, stratify=y_temp)\n",
    "\n",
    "    # create tensors for pytorch\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # create datasets for train, validation, and test\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    # create DataLoader for train, validation, and test\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    class Network(nn.Module):\n",
    "        def __init__(self, input_size: int, output_size: int, hidden_size: int = 128, num_layers: int = 4, dropout: float = 0.2) -> None:\n",
    "            \"\"\"\n",
    "            Initializes a neural network model with specified parameters.\n",
    "\n",
    "            The network consists of an input layer, hidden layers, and an output layer, \n",
    "            with ReLU activations, dropout regularization, and a specified number of layers.\n",
    "\n",
    "            Parameters:\n",
    "            -----------\n",
    "            input_size : int\n",
    "                The number of input features.\n",
    "            \n",
    "            output_size : int\n",
    "                The number of output units (e.g., for classification or regression).\n",
    "            \n",
    "            hidden_size : int, optional, default=128\n",
    "                The number of units in the hidden layers.\n",
    "            \n",
    "            num_layers : int, optional, default=4\n",
    "                The number of hidden layers (currently fixed at 4 for simplicity).\n",
    "            \n",
    "            dropout : float, optional, default=0.2\n",
    "                The dropout rate to apply after each hidden layer.\n",
    "            \"\"\"\n",
    "            super(Network, self).__init__()\n",
    "            \n",
    "            # Initialize layers\n",
    "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "            self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "            self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "            self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "            \n",
    "            # Initialize activation function\n",
    "            self.relu = nn.ReLU()\n",
    "        \n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            \"\"\"\n",
    "            Defines the forward pass of the network.\n",
    "\n",
    "            Parameters:\n",
    "            -----------\n",
    "            x : torch.Tensor\n",
    "                The input tensor to the model.\n",
    "\n",
    "            Returns:\n",
    "            --------\n",
    "            torch.Tensor\n",
    "                The output tensor after passing through the network layers and activation functions.\n",
    "            \"\"\"\n",
    "            x = self.relu(self.fc1(x))  \n",
    "            x = self.dropout(x)        \n",
    "            x = self.relu(self.fc2(x)) \n",
    "            x = self.dropout(x)         \n",
    "            x = self.relu(self.fc3(x))  \n",
    "            x = self.dropout(x)        \n",
    "            x = self.fc4(x)             \n",
    "            return x\n",
    "\n",
    "        def score_function(engine):\n",
    "            val_loss = engine.state.metrics['nll']\n",
    "            return -val_loss\n",
    "\n",
    "\n",
    "    # defining the model\n",
    "    model = Network(input_size=X_train.shape[1], output_size=4)  # output size because we have 4 classes \n",
    "    \n",
    "    # calculating the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # Loss function for classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "    \n",
    "    # training the model, using 100 epochs for each random state\n",
    "    num_epochs = 100\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # using the scheduler to adapt the learning rate dynamically during training\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0 \n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "             # forward Pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # calculate the loss with the loss function\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # backward pass and optimzing weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # evaluate on validation set after each epoch\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                preds = torch.argmax(outputs, axis=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "    # store preds and targets for evaluation on the test set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, axis=1)   # the max. probability defines the predicted class\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    # print the classificiation report\n",
    "    print(f\"Classification Report for Random State {RANDOM_STATE}:\")\n",
    "    print(classification_report(all_targets, all_preds, zero_division=0.0))\n",
    "\n",
    "    # calcualte accuracy and append it to the list to calculate mean and std later\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    accs.append(accuracy)\n",
    "\n",
    "# Calculate mean and std of accuracy scores\n",
    "accs_mean = round(np.mean(accs), 4)\n",
    "accs_std = round(np.std(accs), 4)\n",
    "\n",
    "print(f\"Mean Accuracy: {accs_mean}\")\n",
    "print(f\"Std Accuracy: {accs_std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
