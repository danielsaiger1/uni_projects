{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#PS: Pressure, bar, 100 Hz --> 100 Messungen pro Sekunde\n",
    "#EPS: Motor power, W, 100 Hz \n",
    "#FS: Volume flow, l/min, 10 Hz --> 10 Messungen pro Sekunde\n",
    "#TS: Temperature, Celsius, 1 Hz --> 1 Messung pro Sekunde\n",
    "#VS: Vibration, mm/s, 1Hz\n",
    "#CE: Cooling efficiency (virtual), %, 1 Hz\n",
    "#CP: Cooling power (virtual), kW, 1 Hz\n",
    "#SE: Efficency factor, %, 1 Hz\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, input_path, file_names):\n",
    "        self.input_path = input_path\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def read_files(self):\n",
    "        self.data = {}\n",
    "        print(\"Reading files...\")\n",
    "        for file in self.file_names:\n",
    "            with open(self.input_path + file + '.txt', 'r') as f:\n",
    "                self.data[file] = loadtxt(f)\n",
    "        return self.data\n",
    "    \n",
    "    def print_shape(self):\n",
    "        print(\"Files read:\")\n",
    "        for file in self.data:\n",
    "            print(f\"{file}: {self.data[file].shape}\")\n",
    "            \n",
    "    def create_target_df(self):\n",
    "        target_columns = ['Cooler_Condition', 'Valve_Condition', \n",
    "                        'Internal_Pump_Leakage', 'Hydraulic_Accumulator', \n",
    "                        'Stable_Flag']\n",
    "        self.df_target = pd.DataFrame(self.data['target'], columns=target_columns)\n",
    "        self.valve_condition = self.df_target['Valve_Condition']\n",
    "        del self.data['target']\n",
    "        return self.valve_condition\n",
    "\n",
    "def process_data():\n",
    "    input_path = \"input_data/\"\n",
    "    file_names = [\n",
    "        \"ce\", \"cp\", \"eps1\", \"se\", \"vs1\", \n",
    "        \"fs1\", \"fs2\", \n",
    "        \"ps1\", \"ps2\", \"ps3\", \"ps4\", \"ps5\", \"ps6\",\n",
    "        \"ts1\", \"ts2\", \"ts3\", \"ts4\", \"target\"\n",
    "    ]\n",
    "    \n",
    "    processor = DataProcessor(input_path, file_names)\n",
    "    data = processor.read_files()\n",
    "    processor.print_shape()\n",
    "    processor.create_target_df()\n",
    "    df_target = processor.valve_condition\n",
    "    return data, df_target\n",
    "\n",
    "data, df_target = process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#einzelne Signale in Means abspeichern\n",
    "data_means = {}\n",
    "for key in data:\n",
    "    data_means[key] = np.mean(data[key], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_means['eps1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Funktion: Ausreißer entfernen\n",
    "def remove_outliers(data, threshold=3):\n",
    "    \"\"\"\n",
    "    Entfernt Ausreißer anhand des Z-Scores.\n",
    "    data: 2D-Array (Zeilen: Kanäle, Spalten: Zeitpunkte)\n",
    "    threshold: Schwellenwert für Z-Score\n",
    "    \"\"\"\n",
    "    z_scores = (data - np.mean(data, axis=0, keepdims=True)) / np.std(data, axis=0, keepdims=True)\n",
    "    data_cleaned = np.where(np.abs(z_scores) > threshold, np.median(data, axis=0, keepdims=True), data)\n",
    "    return data_cleaned\n",
    "\n",
    "def smooth_signal(data, window_size=11):\n",
    "    \"\"\"\n",
    "    Glättet das Signal mit einem gleitenden Durchschnitt.\n",
    "    data: 2D-Array (Zeilen: Kanäle, Spalten: Zeitpunkte)\n",
    "    window_size: Fenstergröße für den gleitenden Durchschnitt\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(data).rolling(window=window_size, axis=1, min_periods=1).mean()\n",
    "\n",
    "\n",
    "\n",
    "# Pipeline zur Signalbereinigung\n",
    "def clean_signal(signal):\n",
    "    print(\"1. Entferne Ausreißer...\")\n",
    "    signal_cleaned = remove_outliers(signal)\n",
    "\n",
    "    print(\"2. Glätte das Signal mit Moving Average...\")\n",
    "    signal_smoothed = smooth_signal(signal_cleaned, window_size=10)\n",
    "\n",
    "    return signal_smoothed\n",
    "\n",
    "# # # Visualisierung des Original- und bereinigten Signals\n",
    "# # plt.figure(figsize=(20, 8))\n",
    "# # plt.subplot(2, 1, 1)\n",
    "# # plt.title(\"Originales Signal\")\n",
    "# # plt.plot(signal, alpha=0.3)  # Transponieren für bessere Visualisierung'\n",
    "\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.title(\"Bereinigtes Signal\")\n",
    "# plt.plot(cleaned_signal, alpha=0.3)  # Transponieren für bessere Visualisierung\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order = 5):\n",
    "    return scipy.signal.butter(order, cutoff, fs = fs, btype = 'low', analog = False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order = 5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order = order)\n",
    "    y = scipy.signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "order = 6\n",
    "fs = 100.0\n",
    "cutoff = 3.667\n",
    "\n",
    "y = butter_lowpass_filter(data_means['ts1'], cutoff, fs, order)\n",
    "\n",
    "print(y)\n",
    "# Plots erzeugen\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "\n",
    "# Rohdaten plotten\n",
    "ax[0].plot(data_means['ts1'], 'b-', label='Originaldaten')\n",
    "ax[0].set_title('Originaldaten')\n",
    "\n",
    "# Gefilterte Daten plotten\n",
    "ax[1].plot(y, 'g-', linewidth=2, label='Gefilterte Daten')\n",
    "ax[1].set_title('Gefilterte Daten')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order = 5):\n",
    "    return scipy.signal.butter(order, cutoff, fs = fs, btype = 'low', analog = False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order = 5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order = order)\n",
    "    y = scipy.signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "order = 6\n",
    "fs = 100.0\n",
    "cutoff = 3.667\n",
    "\n",
    "for key in data_means:\n",
    "    data_means[key] = butter_lowpass_filter(data_means[key], cutoff, fs, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualFeatureExtractor:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def extract_features(self):\n",
    "        features = {}\n",
    "        for i, key in enumerate(self.dataset, start=1):\n",
    "            #features[f\"{key}_{i}_mean\"] = self.dataset[key].mean(axis=1)\n",
    "            #features[f\"{key}_{i}_median\"] = np.median(self.dataset[key], axis=1)\n",
    "            features[f\"{key}_{i}_std\"] = self.dataset[key].std(axis=1)\n",
    "            #features[f\"{key}_{i}_min\"] = self.dataset[key].min(axis=1)\n",
    "            #features[f\"{key}_{i}_max\"] = self.dataset[key].max(axis=1)\n",
    "            #features[f\"{key}_{i}_range\"] = self.dataset[key].max(axis=1) - self.dataset[key].min(axis=1)\n",
    "        self.df_features = pd.DataFrame(features)\n",
    "        return self.df_features\n",
    "\n",
    "extractor = ManualFeatureExtractor(data)\n",
    "df_features = extractor.extract_features()\n",
    "print(df_features.shape, df_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "  \n",
    "states = [27, 6728, 49122]\n",
    "accs = []\n",
    "features = df_features\n",
    "target = df_target\n",
    "\n",
    "for RANDOM_STATE in states:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, target, test_size = 0.2, random_state = RANDOM_STATE, stratify = target\n",
    "    )\n",
    "    \n",
    "    model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accs.append(accuracy_score(y_test, preds))\n",
    "    print(f\"Random State: {RANDOM_STATE}\")\n",
    "    print(classification_report(y_test, preds, zero_division=0.0))\n",
    "\n",
    "accs_mean = round(np.mean(accs), 4)\n",
    "accs_std = round(np.std(accs), 4)\n",
    "\n",
    "print(f\"Mean Accuracy: {accs_mean}\")\n",
    "print(f\"Std Accuracy: {accs_std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
