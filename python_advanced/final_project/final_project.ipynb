{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "The data set contains raw process sensor data (i.e. without feature extraction) which are structured as matrices (tab-delimited) with the rows representing the cycles and the columns the data points within a cycle. The sensors involved are:\n",
    "\n",
    "Sensor\t\tPhysical quantity\t\tUnit\t\tSampling rate\n",
    "PS1\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS2\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS3\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS4\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS5\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS6\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "EPS1\t\tMotor power\t\t\tW\t\t100 Hz\n",
    "FS1\t\tVolume flow\t\t\tl/min\t\t10 Hz\n",
    "FS2\t\tVolume flow\t\t\tl/min\t\t10 Hz\n",
    "TS1\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "TS2\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "TS3\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "TS4\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "VS1\t\tVibration\t\t\tmm/s\t\t1 Hz\n",
    "CE\t\tCooling efficiency (virtual)\t%\t\t1 Hz\n",
    "CP\t\tCooling power (virtual)\t\tkW\t\t1 Hz\n",
    "SE\t\tEfficiency factor\t\t%\t\t1 Hz\n",
    "\n",
    "\n",
    "\n",
    "Has Missing Values?\n",
    "\n",
    "No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class DataProcessor:\n",
    "    def __init__(self, input_path, file_names):\n",
    "        self.input_path = input_path\n",
    "        self.file_names = file_names\n",
    "        \n",
    "        \n",
    "    def read_files(self):\n",
    "        self.data = {}\n",
    "        for file in self.file_names:\n",
    "            with open(self.input_path + file, 'r') as f:\n",
    "                data[f] = loadtxt(f\"{self.input_path}{self.file_name}.txt\")\n",
    "        return self.data\n",
    "    \n",
    "    def print_shape(self):\n",
    "        for file in self.data:\n",
    "            print(f\"{file}: {self.data[file].shape}\")\n",
    "            \n",
    "    def create_target_df(self):\n",
    "        try:\n",
    "            target_columns = ['Cooler_Condition', 'Valve_Condition', \n",
    "                            'Internal_Pump_Leakage', 'Hydraulic_Accumulator', \n",
    "                            'Stable_Flag']\n",
    "            self.df_target = pd.DataFrame(self.data['target'], columns=target_columns)\n",
    "            self.df_target = df_target['Valve_Condition']\n",
    "            del self.data['target']\n",
    "            return self.df_target\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten von 'target': {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#PS: Pressure, bar, 100 Hz --> 100 Messungen pro Skeunde\n",
    "#EPS: Motor power, W, 100 Hz\n",
    "#FS: Volume flow, l/min, 10 Hz --> 10 Messungen pro Sekunde\n",
    "#TS: Temperature, Celsius, 1 Hz --> 1 Messung pro Sekunde\n",
    "#VS: Vibration, mm/s, 1Hz\n",
    "#CE: Cooling efficiency (virtual), %, 1 Hz\n",
    "#CP: Cooling power (virtual), kW, 1 Hz\n",
    "#SE: Efficency factor, %, 1 Hz\n",
    "\n",
    "\n",
    "input_path = \"input_data/\"\n",
    "file_names = [\n",
    "    \"ce\", \"cp\", \"eps1\", \"se\", \"vs1\", \n",
    "    \"fs1\", \"fs2\", \n",
    "    \"ps1\", \"ps2\", \"ps3\", \"ps4\", \"ps5\", \"ps6\",\n",
    "    \"ts1\", \"ts2\", \"ts3\", \"ts4\", \"target\"\n",
    "]\n",
    "\n",
    "data = {}\n",
    "\n",
    "for file_name in file_names:\n",
    "    data[file_name] = loadtxt(f\"{input_path}{file_name}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ce:(2205, 60)\n",
      "Shape of cp:(2205, 60)\n",
      "Shape of eps1:(2205, 6000)\n",
      "Shape of se:(2205, 60)\n",
      "Shape of vs1:(2205, 60)\n",
      "Shape of fs1:(2205, 600)\n",
      "Shape of fs2:(2205, 600)\n",
      "Shape of ps1:(2205, 6000)\n",
      "Shape of ps2:(2205, 6000)\n",
      "Shape of ps3:(2205, 6000)\n",
      "Shape of ps4:(2205, 6000)\n",
      "Shape of ps5:(2205, 6000)\n",
      "Shape of ps6:(2205, 6000)\n",
      "Shape of ts1:(2205, 60)\n",
      "Shape of ts2:(2205, 60)\n",
      "Shape of ts3:(2205, 60)\n",
      "Shape of ts4:(2205, 60)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m file_names:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[file_name]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "for file_name in file_names:\n",
    "    print(f\"Shape of {file_name}:{data[file_name].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    target_columns = ['Cooler_Condition', 'Valve_Condition', \n",
    "                      'Internal_Pump_Leakage', 'Hydraulic_Accumulator', \n",
    "                      'Stable_Flag']\n",
    "    df_target = pd.DataFrame(data['target'], columns=target_columns)\n",
    "    df_target = df_target['Valve_Condition']  # Nur 'Valve_Condition' verwenden\n",
    "    del data['target']  # 'target' aus den übrigen Daten entfernen\n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Verarbeiten von 'target': {e}\")\n",
    "\n",
    "#df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 3, figsize=(15, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, key in enumerate(data):\n",
    "    ax = axes[i]\n",
    "    ax.plot(data[key], color = 'blue', linewidth = 1)\n",
    "    ax.plot(np.mean(data[key], axis=1), color = 'red') \n",
    "    ax.set_title(key) \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, array in data.items():\n",
    "    print(f\"{key}: Mean = {round((np.mean(array)),4)}, Std = {round((np.std(array)),4)}, Min = {np.min(array)}, Max = {np.max(array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key in data: \n",
    "    # Erstelle ein 2D-Array (zum Beispiel ein einfaches Bild oder eine Matrix)\n",
    "    image = data[key]\n",
    "\n",
    "    # Berechne die 2D-Fourier-Transformation\n",
    "    f_transform = np.fft.fft2(image)\n",
    "\n",
    "    # Verschiebe den Nullfrequenzanteil in die Mitte des Spektrums\n",
    "    f_transform_shifted = np.fft.fftshift(f_transform)\n",
    "\n",
    "    # Berechne das Magnitudespektrum (Betrag)\n",
    "    magnitude_spectrum = np.abs(f_transform_shifted)\n",
    "\n",
    "    # Berechne das Phasenspektrum (Phase)\n",
    "    phase_spectrum = np.angle(f_transform_shifted)\n",
    "\n",
    "    # Summiere das Magnitudespektrum entlang der Spalten (horizontale Richtung)\n",
    "    magnitude_spectrum_sum_cols = np.sum(magnitude_spectrum, axis=0)\n",
    "\n",
    "    # Plot des Magnitudespektrums als Summe entlang der Spalten\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(magnitude_spectrum_sum_cols)\n",
    "    plt.title(f\"{key}: Magnitude Spectrum (Summe entlang der Spalten)\")\n",
    "    plt.xlabel(\"Spalten-Index\")\n",
    "    plt.ylabel(\"Summierte Magnitude\")\n",
    "\n",
    "    # Plot des Phasenspektrums\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(phase_spectrum, cmap='twilight', aspect='auto')\n",
    "    plt.title(f\"{key}: Phase Spectrum\")\n",
    "    plt.colorbar(label='Phase (radians)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle ein Dictionary für alle Features\n",
    "features = {}\n",
    "\n",
    "# Iteriere über alle Keys im `data` Dictionary\n",
    "for idx, key in enumerate(data, start=1):\n",
    "    # Berechne die gewünschten Statistiken für jede Zeile (axis=1)\n",
    "    #features[f\"{key}_{idx}_mean\"] = data[key].mean(axis=1)\n",
    "    #features[f\"{key}_{idx}_median\"] = np.median(data[key], axis=1)\n",
    "    features[f\"{key}_{idx}_std\"] = data[key].std(axis=1)\n",
    "    #features[f\"{key}_{idx}_min\"] = data[key].min(axis=1)\n",
    "    #features[f\"{key}_{idx}_max\"] = data[key].max(axis=1)\n",
    "    #features[f\"{key}_{idx}_range\"] = data[key].max(axis=1) - data[key].min(axis=1)\n",
    "\n",
    "# Konvertiere das `features` Dictionary in einen DataFrame\n",
    "df_features = pd.DataFrame(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2205, 17) (2205,)\n"
     ]
    }
   ],
   "source": [
    "print(df_features.shape, df_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\py_adv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8163265306122449\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        73.0       1.00      0.67      0.80        88\n",
      "        80.0       0.71      0.96      0.82        67\n",
      "        90.0       0.74      0.62      0.68        80\n",
      "       100.0       0.83      0.91      0.87       206\n",
      "\n",
      "    accuracy                           0.82       441\n",
      "   macro avg       0.82      0.79      0.79       441\n",
      "weighted avg       0.83      0.82      0.81       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Extrahierte Features und Labels (ersetze dies mit deinem Datensatz)\n",
    "\n",
    "# Features und Zielvariable\n",
    "X = df_features\n",
    "y = df_target\n",
    "\n",
    "X.shape\n",
    "\n",
    "y.shape\n",
    "\n",
    "# Datenaufteilung\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# AdaBoost-Modell\n",
    "ada_model = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\n",
    "\n",
    "# Training\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred = ada_model.predict(X_test)\n",
    "\n",
    "# Modellbewertung\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
