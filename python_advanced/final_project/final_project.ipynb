{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "The data set contains raw process sensor data (i.e. without feature extraction) which are structured as matrices (tab-delimited) with the rows representing the cycles and the columns the data points within a cycle. The sensors involved are:\n",
    "\n",
    "Sensor\t\tPhysical quantity\t\tUnit\t\tSampling rate\n",
    "PS1\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS2\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS3\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS4\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS5\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "PS6\t\tPressure\t\t\tbar\t\t100 Hz\n",
    "EPS1\t\tMotor power\t\t\tW\t\t100 Hz\n",
    "FS1\t\tVolume flow\t\t\tl/min\t\t10 Hz\n",
    "FS2\t\tVolume flow\t\t\tl/min\t\t10 Hz\n",
    "TS1\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "TS2\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "TS3\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "TS4\t\tTemperature\t\t\tÂ°C\t\t1 Hz\n",
    "VS1\t\tVibration\t\t\tmm/s\t\t1 Hz\n",
    "CE\t\tCooling efficiency (virtual)\t%\t\t1 Hz\n",
    "CP\t\tCooling power (virtual)\t\tkW\t\t1 Hz\n",
    "SE\t\tEfficiency factor\t\t%\t\t1 Hz\n",
    "\n",
    "\n",
    "\n",
    "Has Missing Values?\n",
    "\n",
    "No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#PS: Pressure, bar, 100 Hz --> 100 Messungen pro Skeunde\n",
    "#EPS: Motor power, W, 100 Hz\n",
    "#FS: Volume flow, l/min, 10 Hz --> 10 Messungen pro Sekunde\n",
    "#TS: Temperature, Celsius, 1 Hz --> 1 Messung pro Sekunde\n",
    "#VS: Vibration, mm/s, 1Hz\n",
    "#CE: Cooling efficiency (virtual), %, 1 Hz\n",
    "#CP: Cooling power (virtual), kW, 1 Hz\n",
    "#SE: Efficency factor, %, 1 Hz\n",
    "\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, input_path, file_names):\n",
    "        self.input_path = input_path\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def read_files(self):\n",
    "        self.data = {}\n",
    "        print(\"Reading files...\")\n",
    "        for file in self.file_names:\n",
    "            with open(self.input_path + file + '.txt', 'r') as f:\n",
    "                self.data[file] = loadtxt(f)\n",
    "        return self.data\n",
    "    \n",
    "    def print_shape(self):\n",
    "        print(\"Files read:\")\n",
    "        for file in self.data:\n",
    "            print(f\"{file}: {self.data[file].shape}\")\n",
    "            \n",
    "    def create_target_df(self):\n",
    "        target_columns = ['Cooler_Condition', 'Valve_Condition', \n",
    "                        'Internal_Pump_Leakage', 'Hydraulic_Accumulator', \n",
    "                        'Stable_Flag']\n",
    "        self.df_target = pd.DataFrame(self.data['target'], columns=target_columns)\n",
    "        self.valve_condition = self.df_target['Valve_Condition']\n",
    "        del self.data['target']\n",
    "        return self.valve_condition\n",
    "\n",
    "def process_data():\n",
    "    input_path = \"input_data/\"\n",
    "    file_names = [\n",
    "        \"ce\", \"cp\", \"eps1\", \"se\", \"vs1\", \n",
    "        \"fs1\", \"fs2\", \n",
    "        \"ps1\", \"ps2\", \"ps3\", \"ps4\", \"ps5\", \"ps6\",\n",
    "        \"ts1\", \"ts2\", \"ts3\", \"ts4\", \"target\"\n",
    "    ]\n",
    "    \n",
    "    processor = DataProcessor(input_path, file_names)\n",
    "    data = processor.read_files()\n",
    "    processor.print_shape()\n",
    "    processor.create_target_df()\n",
    "    df_target = processor.valve_condition\n",
    "    return data, df_target\n",
    "\n",
    "data, df_target = process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPlotter:\n",
    "    def __init__(self, dataset: dict):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def create_subplot(self):\n",
    "        fig, axs = plt.subplots(6, 3, figsize=(15, 20))\n",
    "        axes = axs.flatten()  \n",
    "        for i, key in enumerate(self.dataset):\n",
    "            ax = axes[i]\n",
    "            ax.plot(self.dataset[key], color='blue', linewidth=1)\n",
    "            ax.plot(np.mean(self.dataset[key], axis=1), color='red')\n",
    "            ax.set_title(key)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def create_fft_plot(self):\n",
    "        for key in self.dataset: \n",
    "            # Erstelle ein 2D-Array (z. B. eine Matrix)\n",
    "            image = self.dataset[key]\n",
    "            # 2D-Fourier-Transformation\n",
    "            f_transform = np.fft.fft2(image)\n",
    "            # Verschiebe den Nullfrequenzanteil in die Mitte des Spektrums\n",
    "            f_transform_shifted = np.fft.fftshift(f_transform)\n",
    "            # Berechne das Magnitudespektrum (Betrag)\n",
    "            magnitude_spectrum = np.abs(f_transform_shifted)\n",
    "            # Berechne das Phasenspektrum (Phase)\n",
    "            phase_spectrum = np.angle(f_transform_shifted)\n",
    "            # Summiere das Magnitudespektrum entlang der Spalten (horizontale Richtung)\n",
    "            magnitude_spectrum_sum_cols = np.sum(magnitude_spectrum, axis=0)\n",
    "            \n",
    "            # Plots\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            # Magnitudespektrum\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(magnitude_spectrum_sum_cols)\n",
    "            plt.title(f\"{key}: Magnitude Spectrum (Summe entlang der Spalten)\")\n",
    "            plt.xlabel(\"Spalten-Index\")\n",
    "            plt.ylabel(\"Summierte Magnitude\")\n",
    "            # Phasenspektrum\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(phase_spectrum, cmap='twilight', aspect='auto')\n",
    "            plt.title(f\"{key}: Phase Spectrum\")\n",
    "            plt.colorbar(label='Phase (radians)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "plot = DataPlotter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.create_subplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.create_fft_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, array in data.items():\n",
    "    print(f\"{key}: Mean = {round((np.mean(array)),4)}, Std = {round((np.std(array)),4)}, Min = {np.min(array)}, Max = {np.max(array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualFeatureExtractor:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def extract_features(self):\n",
    "        features = {}\n",
    "        for i, key in enumerate(self.dataset, start=1):\n",
    "            #features[f\"{key}_{i}_mean\"] = self.dataset[key].mean(axis=1)\n",
    "            #features[f\"{key}_{i}_median\"] = np.median(self.dataset[key], axis=1)\n",
    "            features[f\"{key}_{i}_std\"] = self.dataset[key].std(axis=1)\n",
    "            #features[f\"{key}_{i}_min\"] = self.dataset[key].min(axis=1)\n",
    "            #features[f\"{key}_{i}_max\"] = self.dataset[key].max(axis=1)\n",
    "            #features[f\"{key}_{i}_range\"] = self.dataset[key].max(axis=1) - self.dataset[key].min(axis=1)\n",
    "        self.df_features = pd.DataFrame(features)\n",
    "        return self.df_features\n",
    "\n",
    "extractor = ManualFeatureExtractor(data)\n",
    "df_features = extractor.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_features.shape, df_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "    \n",
    "    def split_data(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.features, self.target, test_size=0.2, random_state=42\n",
    "        )\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def build_model(self):\n",
    "        X_train, X_test, y_train, y_test = self.split_data()\n",
    "        \n",
    "        model = AdaBoostClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=1),\n",
    "            n_estimators=50,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "        return model \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features\n",
    "Y = df_target\n",
    "builder = ModelBuilder(X,y)\n",
    "model = builder.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merker für nach Urlaub: Datensätze von Sensoren, die mehrere Aufzeichnungen haben, zusammenführen, um einen großen Datensatz zu erhalten. Daraus dann wieder Standardabweichungen berechnen und in das Modell geben"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
