{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Classification using TimeMixer </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"img/time_mixer.png\" width=\"1000\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Imports and load data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Files read:\n",
      "ce: (2205, 60)\n",
      "cp: (2205, 60)\n",
      "eps1: (2205, 6000)\n",
      "se: (2205, 60)\n",
      "vs1: (2205, 60)\n",
      "fs1: (2205, 600)\n",
      "fs2: (2205, 600)\n",
      "ps1: (2205, 6000)\n",
      "ps2: (2205, 6000)\n",
      "ps3: (2205, 6000)\n",
      "ps4: (2205, 6000)\n",
      "ps5: (2205, 6000)\n",
      "ps6: (2205, 6000)\n",
      "ts1: (2205, 60)\n",
      "ts2: (2205, 60)\n",
      "ts3: (2205, 60)\n",
      "ts4: (2205, 60)\n",
      "target: (2205, 5)\n"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, input_path, file_names):\n",
    "        self.input_path = input_path\n",
    "        self.file_names = file_names\n",
    "        \n",
    "    def read_files(self):\n",
    "        self.data = {}\n",
    "        print(\"Reading files...\")\n",
    "        for file in self.file_names:\n",
    "            with open(self.input_path + file + '.txt', 'r') as f:\n",
    "                self.data[file] = pd.read_csv(f, header=None, sep='\\t')\n",
    "        return self.data\n",
    "    \n",
    "    def print_shape(self):\n",
    "        print(\"Files read:\")\n",
    "        for file in self.data:\n",
    "            print(f\"{file}: {self.data[file].shape}\")\n",
    "            \n",
    "    def create_target_df(self):\n",
    "        target_columns = ['Cooler_Condition', 'Valve_Condition', \n",
    "                        'Internal_Pump_Leakage', 'Hydraulic_Accumulator', \n",
    "                        'Stable_Flag']\n",
    "        self.data['target'].columns = target_columns\n",
    "        self.valve_condition = self.data['target']['Valve_Condition']\n",
    "        #del self.data['target']\n",
    "        return self.valve_condition\n",
    "\n",
    "def process_data():\n",
    "    input_path = \"input_data/\"\n",
    "    file_names = [\n",
    "        \"ce\", \"cp\", \"eps1\", \"se\", \"vs1\", \n",
    "        \"fs1\", \"fs2\", \n",
    "        \"ps1\", \"ps2\", \"ps3\", \"ps4\", \"ps5\", \"ps6\",\n",
    "        \"ts1\", \"ts2\", \"ts3\", \"ts4\", \"target\"\n",
    "    ]\n",
    "    \n",
    "    processor = DataProcessor(input_path, file_names)\n",
    "    data = processor.read_files()\n",
    "    processor.print_shape()\n",
    "    df_target = processor.create_target_df()\n",
    "    df_target = processor.valve_condition\n",
    "    return data, df_target\n",
    "\n",
    "data, df_target = process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create input and target data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the six sensors 'eps1', 'se', 'fs1', 'ps1', 'ps2', 'ps3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2411.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.383</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>2409.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.195</td>\n",
       "      <td>2.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2397.8</td>\n",
       "      <td>2395.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.391</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.320</td>\n",
       "      <td>2.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2383.8</td>\n",
       "      <td>2382.8</td>\n",
       "      <td>2382.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.117</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.141</td>\n",
       "      <td>2.172</td>\n",
       "      <td>2.187</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>2416.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.375</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.383</td>\n",
       "      <td>2.359</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.297</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.406</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>2413.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.281</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.242</td>\n",
       "      <td>2.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>2415.8</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>2415.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.336</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.195</td>\n",
       "      <td>2.266</td>\n",
       "      <td>2.305</td>\n",
       "      <td>2.320</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.227</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2205 rows × 24660 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8     \\\n",
       "0     2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6  2411.6   \n",
       "1     2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6  2409.6   \n",
       "2     2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8  2397.8   \n",
       "3     2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2383.8  2382.8   \n",
       "4     2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0  2372.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2200  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4  2416.4   \n",
       "2201  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6   \n",
       "2202  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6   \n",
       "2203  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6  2413.6   \n",
       "2204  2415.8  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6  2415.6   \n",
       "\n",
       "        9     ...   5990   5991   5992   5993   5994   5995   5996   5997  \\\n",
       "0     2409.6  ...  2.336  2.391  2.375  2.297  2.328  2.383  2.328  2.250   \n",
       "1     2409.6  ...  2.297  2.266  2.266  2.219  2.211  2.266  2.273  2.211   \n",
       "2     2395.8  ...  2.359  2.391  2.391  2.375  2.375  2.375  2.305  2.305   \n",
       "3     2382.8  ...  2.117  2.219  2.281  2.227  2.164  2.164  2.219  2.250   \n",
       "4     2373.0  ...  2.141  2.172  2.187  2.227  2.219  2.211  2.242  2.219   \n",
       "...      ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2200  2416.4  ...  2.328  2.305  2.328  2.359  2.375  2.281  2.242  2.250   \n",
       "2201  2415.6  ...  2.273  2.383  2.359  2.297  2.297  2.336  2.406  2.461   \n",
       "2202  2413.6  ...  2.227  2.242  2.219  2.211  2.273  2.273  2.250  2.219   \n",
       "2203  2413.6  ...  2.328  2.328  2.328  2.281  2.266  2.305  2.281  2.250   \n",
       "2204  2415.6  ...  2.336  2.336  2.250  2.195  2.266  2.305  2.320  2.273   \n",
       "\n",
       "       5998   5999  \n",
       "0     2.250  2.211  \n",
       "1     2.195  2.219  \n",
       "2     2.320  2.266  \n",
       "3     2.273  2.273  \n",
       "4     2.227  2.297  \n",
       "...     ...    ...  \n",
       "2200  2.266  2.273  \n",
       "2201  2.461  2.406  \n",
       "2202  2.219  2.250  \n",
       "2203  2.242  2.281  \n",
       "2204  2.227  2.250  \n",
       "\n",
       "[2205 rows x 24660 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = ['eps1', 'se', 'fs1', 'ps1', 'ps2', 'ps3']\n",
    "input_df = pd.concat([data[i] for i in df_list], axis = 1)\n",
    "input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise the input and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_target)\n",
    "\n",
    "# Standatdise the input\n",
    "scaler = StandardScaler()\n",
    "input_data_scaled = scaler.fit_transform(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create the model, train it & make predictions </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>With the TimeMixer Module we create a neural network with 1 input layer, 2 hidden layers and 1 output layer --> 4 layers total\n",
    "<li>We use the stochastic gradient descent with a middle-sized batch size of 32 since we dont have a very big data set\n",
    "<li>We use CrossEntropyLoss() for calculcating the loss. It uses the softmax function. Because of that, we don't have to use the softmax function in our output layer for classification by using the probabilities\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for random state 27:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        72\n",
      "           1       1.00      0.99      0.99        72\n",
      "           2       1.00      0.99      0.99        72\n",
      "           3       1.00      1.00      1.00       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n",
      "Classification Report for random state 6728:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        72\n",
      "           1       0.99      1.00      0.99        72\n",
      "           2       0.97      0.96      0.97        72\n",
      "           3       0.99      1.00      0.99       225\n",
      "\n",
      "    accuracy                           0.99       441\n",
      "   macro avg       0.99      0.99      0.99       441\n",
      "weighted avg       0.99      0.99      0.99       441\n",
      "\n",
      "Classification Report for random state 49122:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        72\n",
      "           1       0.99      1.00      0.99        72\n",
      "           2       1.00      1.00      1.00        72\n",
      "           3       1.00      1.00      1.00       225\n",
      "\n",
      "    accuracy                           1.00       441\n",
      "   macro avg       1.00      1.00      1.00       441\n",
      "weighted avg       1.00      1.00      1.00       441\n",
      "\n",
      "Mean Accuracy: 0.9932\n",
      "Std Accuracy: 0.0037\n"
     ]
    }
   ],
   "source": [
    "states = [27, 6728, 49122]\n",
    "\n",
    "accs = []\n",
    "\n",
    "for RANDOM_STATE in states:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_data_scaled, y_encoded, test_size=0.2, random_state=RANDOM_STATE, stratify=y_encoded)\n",
    "\n",
    "    # Create tensors for pytorch\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # with tensors create train and test dataset\n",
    "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    # implementing the timemixer model\n",
    "    class TimeMixer(nn.Module):\n",
    "        def __init__(self, input_size, output_size, hidden_size=128, num_layers=4, dropout=0.2):\n",
    "            super(TimeMixer, self).__init__()\n",
    "            \n",
    "            # create 1 input layer, 2 hidden layers and 1 output layer \n",
    "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "            self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "            self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "            self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "            \n",
    "            # create the activation function\n",
    "            self.relu = nn.ReLU()\n",
    "        \n",
    "        # forward pass\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.relu(self.fc2(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.relu(self.fc3(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc4(x)\n",
    "            return x\n",
    "\n",
    "    # defining the model\n",
    "    model = TimeMixer(input_size=X_train.shape[1], output_size=4)  # Output size = Anzahl Klassen \n",
    "    \n",
    "    # calculating the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # lossfunction for classification (CrossEntropyLoss is using softmax, which is why dont use softmax in the ouptut layer)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "    # training the model, using 100 epochs for each random state\n",
    "    num_epochs = 100\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1) # using the scheduler to adapt the learning rate dynamically during training\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0 \n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate the loss with the loss function\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward Pass and optimzing weights and biases\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "    # Store preds and targets for evaluation with classification report\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            preds = torch.argmax(outputs, axis=1)  # The max. probability defines the predicted class\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    # print the classificiation report\n",
    "    print(f\"Classification Report for random state {RANDOM_STATE}:\")\n",
    "    print(classification_report(all_targets, all_preds, zero_division=0.0))\n",
    "\n",
    "    # Calcualte accuracy and append it to the list to calculate mean and std later\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    accs.append(accuracy)\n",
    "\n",
    "accs_mean = round(np.mean(accs), 4)\n",
    "accs_std = round(np.std(accs), 4)\n",
    "\n",
    "print(f\"Mean Accuracy: {accs_mean}\")\n",
    "print(f\"Std Accuracy: {accs_std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
